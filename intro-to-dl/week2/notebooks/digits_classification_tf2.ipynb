{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digits_classification_tf2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM7iBSvtKxAtIwhlMZGzM1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyyeh/advanced-ml/blob/master/intro-to-dl/week2/notebooks/digits_classification_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMasL5D6RiP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b284cbf9-44c0-4a85-ce83-d75f75fe639e"
      },
      "source": [
        "# set tf 2.x for colab\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkesvqZtRwKZ",
        "colab_type": "text"
      },
      "source": [
        "# MNIST digits classification with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TFE8DtPR0Df",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/cyyeh/advanced-ml/blob/master/intro-to-dl/week2/notebooks/v2/images/mnist_sample.png?raw=1\" style=\"width:30%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJDqVCwvRrsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7d5f84f-7d3e-43c2-9065-62457d2d4225"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "print(\"We're using TF\", tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using TF 2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm4ZeiWTSDVq",
        "colab_type": "text"
      },
      "source": [
        "# Look at the data\n",
        "\n",
        "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
        "We will train a classifier on this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8zpp7SVR98Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(\n",
        "    path='mnist.npz'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0wFrKmpSfld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45cb341c-33f4-47dc-8134-bf2b8e8f4220"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz9Z8YfaTkid",
        "colab_type": "text"
      },
      "source": [
        "Normalize data and reserve the last 10000 training examples for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdDDgygHTXCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize x\n",
        "X_train = X_train.astype(float) / 255.\n",
        "X_test = X_test.astype(float) / 255.\n",
        "\n",
        "# we reserve the last 10000 training examples for validation\n",
        "X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
        "y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
        "\n",
        "assert X_train.shape[0] == 50000, f\"X_train size should be 50000, but we got {X_train.shape[0]}\"\n",
        "assert X_val.shape[0] == 10000, f\"X_val size should be 10000, but we got {X_val.shape[0]}\"\n",
        "assert y_train.shape[0] == 50000, f\"y_train size should be 50000, but we got {y_train.shape[0]}\"\n",
        "assert y_val.shape[0] == 10000, f\"y_val size should be 10000, but we got {y_val.shape[0]}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5zpf1ceT0OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "1296adda-dd8d-4b84-920a-6880bc9bba56"
      },
      "source": [
        "# X contains rgb values divided by 255\n",
        "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
        "print(\"A closeup of a sample patch:\")\n",
        "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"And the whole sample:\")\n",
        "plt.imshow(X_train[1], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train [shape (50000, 28, 28)] sample patch:\n",
            " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
            " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
            " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
            " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
            " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
            "A closeup of a sample patch:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "And the whole sample:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8PJdJc1jCDmVwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "y_train [shape (50000,)] 10 samples:\n",
            " [5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPTZOQ3IU9Zq",
        "colab_type": "text"
      },
      "source": [
        "# Linear model\n",
        "\n",
        "Your task is to train a linear classifier $\\vec{x} \\rightarrow y$ with SGD using TensorFlow.\n",
        "\n",
        "You will need to calculate a logit (a linear transformation) $z_k$ for each class: \n",
        "$$z_k = \\vec{x} \\cdot \\vec{w_k} + b_k \\quad k = 0..9$$\n",
        "\n",
        "And transform logits $z_k$ to valid probabilities $p_k$ with softmax: \n",
        "$$p_k = \\frac{e^{z_k}}{\\sum_{i=0}^{9}{e^{z_i}}} \\quad k = 0..9$$\n",
        "\n",
        "We will use a cross-entropy loss to train our multi-class classifier:\n",
        "$$\\text{cross-entropy}(y, p) = -\\sum_{k=0}^{9}{\\log(p_k)[y = k]}$$ \n",
        "\n",
        "where \n",
        "$$\n",
        "[x]=\\begin{cases}\n",
        "       1, \\quad \\text{if $x$ is true} \\\\\n",
        "       0, \\quad \\text{otherwise}\n",
        "    \\end{cases}\n",
        "$$\n",
        "\n",
        "Cross-entropy minimization pushes $p_k$ close to 1 when $y = k$, which is what we want.\n",
        "\n",
        "Here's the plan:\n",
        "* Flatten the images (28x28 -> 784) with `X_train.reshape((X_train.shape[0], -1))` to simplify our linear model implementation\n",
        "* Use a matrix placeholder for flattened `X_train`\n",
        "* Convert `y_train` to one-hot encoded vectors that are needed for cross-entropy\n",
        "* Use a shared variable `W` for all weights (a column $\\vec{w_k}$ per class) and `b` for all biases.\n",
        "* Aim for ~0.93 validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvIiPf34UwRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f3567d8-d567-4946-a3d0-f18dfd9a36f9"
      },
      "source": [
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "print(X_train_flat.shape)\n",
        "\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
        "print(X_val_flat.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j26BBJb6VN_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8ce3635b-610e-4e95-fbff-4c0bf520f475"
      },
      "source": [
        "# one-hot encoding\n",
        "y_train_oh = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_val_oh = tf.keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "print(y_train_oh[:3], y_train[:3])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXPWlFhYb-Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 40\n",
        "BATCH_SIZE = 512\n",
        "BUFFER_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFPHT-K_hSf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_train_flat, y_train_oh))\n",
        "    .shuffle(buffer_size=BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "val_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_val_flat, y_val_oh))\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eOsq1tHbnTC",
        "colab_type": "text"
      },
      "source": [
        "# Method 1 For Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-f3BoVVnZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec5a7710-7038-41e7-ab29-e37b8eb2e3b9"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 98 steps, validate for 20 steps\n",
            "Epoch 1/40\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5360 - accuracy: 0.8594 - val_loss: 0.2476 - val_accuracy: 0.9317\n",
            "Epoch 2/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2316 - accuracy: 0.9352 - val_loss: 0.1893 - val_accuracy: 0.9496\n",
            "Epoch 3/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1760 - accuracy: 0.9503 - val_loss: 0.1550 - val_accuracy: 0.9587\n",
            "Epoch 4/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1418 - accuracy: 0.9590 - val_loss: 0.1364 - val_accuracy: 0.9634\n",
            "Epoch 5/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1182 - accuracy: 0.9663 - val_loss: 0.1217 - val_accuracy: 0.9673\n",
            "Epoch 6/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0998 - accuracy: 0.9725 - val_loss: 0.1128 - val_accuracy: 0.9696\n",
            "Epoch 7/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0852 - accuracy: 0.9764 - val_loss: 0.1048 - val_accuracy: 0.9713\n",
            "Epoch 8/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9799 - val_loss: 0.0993 - val_accuracy: 0.9721\n",
            "Epoch 9/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.0943 - val_accuracy: 0.9722\n",
            "Epoch 10/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0570 - accuracy: 0.9848 - val_loss: 0.0905 - val_accuracy: 0.9734\n",
            "Epoch 11/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9871 - val_loss: 0.0867 - val_accuracy: 0.9751\n",
            "Epoch 12/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9888 - val_loss: 0.0835 - val_accuracy: 0.9748\n",
            "Epoch 13/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9904 - val_loss: 0.0821 - val_accuracy: 0.9769\n",
            "Epoch 14/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9918 - val_loss: 0.0818 - val_accuracy: 0.9764\n",
            "Epoch 15/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9929 - val_loss: 0.0815 - val_accuracy: 0.9768\n",
            "Epoch 16/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9938 - val_loss: 0.0800 - val_accuracy: 0.9773\n",
            "Epoch 17/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9948 - val_loss: 0.0793 - val_accuracy: 0.9762\n",
            "Epoch 18/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9955 - val_loss: 0.0794 - val_accuracy: 0.9769\n",
            "Epoch 19/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0203 - accuracy: 0.9963 - val_loss: 0.0785 - val_accuracy: 0.9775\n",
            "Epoch 20/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9970 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
            "Epoch 21/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 0.0798 - val_accuracy: 0.9769\n",
            "Epoch 22/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 0.0786 - val_accuracy: 0.9779\n",
            "Epoch 23/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9984 - val_loss: 0.0806 - val_accuracy: 0.9768\n",
            "Epoch 24/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
            "Epoch 25/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0847 - val_accuracy: 0.9769\n",
            "Epoch 26/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0840 - val_accuracy: 0.9772\n",
            "Epoch 27/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.0863 - val_accuracy: 0.9768\n",
            "Epoch 28/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.0835 - val_accuracy: 0.9780\n",
            "Epoch 29/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9779\n",
            "Epoch 30/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.0850 - val_accuracy: 0.9781\n",
            "Epoch 31/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.0855 - val_accuracy: 0.9780\n",
            "Epoch 32/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.0850 - val_accuracy: 0.9791\n",
            "Epoch 33/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0840 - val_accuracy: 0.9794\n",
            "Epoch 34/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0845 - val_accuracy: 0.9791\n",
            "Epoch 35/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0862 - val_accuracy: 0.9789\n",
            "Epoch 36/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0864 - val_accuracy: 0.9792\n",
            "Epoch 37/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0855 - val_accuracy: 0.9792\n",
            "Epoch 38/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0858 - val_accuracy: 0.9801\n",
            "Epoch 39/40\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9791\n",
            "Epoch 40/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6edbee7eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PITx7MufcHLS",
        "colab_type": "text"
      },
      "source": [
        "# Method 2 For Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODFYZp4lZO5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class DigitsClassificationMLP(keras.models.Model):\n",
        "  def __init__(self, units=256, activation='relu', **kwargs):\n",
        "    super(DigitsClassificationMLP, self).__init__(**kwargs)\n",
        "    self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "    self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "    self.main_outputs = keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    hidden1_out = self.hidden1(inputs)\n",
        "    hidden2_out = self.hidden2(hidden1_out)\n",
        "    outputs = self.main_outputs(hidden2_out)\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zrYgcYKdQ0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7046be0a-76a4-411a-9de4-2423abba3140"
      },
      "source": [
        "# initiate the model\n",
        "model = DigitsClassificationMLP()\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 98 steps, validate for 20 steps\n",
            "Epoch 1/40\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4726 - accuracy: 0.8717 - val_loss: 0.1950 - val_accuracy: 0.9454\n",
            "Epoch 2/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1840 - accuracy: 0.9464 - val_loss: 0.1401 - val_accuracy: 0.9601\n",
            "Epoch 3/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9627 - val_loss: 0.1151 - val_accuracy: 0.9661\n",
            "Epoch 4/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0944 - accuracy: 0.9733 - val_loss: 0.1018 - val_accuracy: 0.9703\n",
            "Epoch 5/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 0.0992 - val_accuracy: 0.9705\n",
            "Epoch 6/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0565 - accuracy: 0.9835 - val_loss: 0.0937 - val_accuracy: 0.9736\n",
            "Epoch 7/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.0946 - val_accuracy: 0.9731\n",
            "Epoch 8/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 0.0937 - val_accuracy: 0.9747\n",
            "Epoch 9/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0299 - accuracy: 0.9918 - val_loss: 0.0947 - val_accuracy: 0.9733\n",
            "Epoch 10/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.0924 - val_accuracy: 0.9754\n",
            "Epoch 11/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.0904 - val_accuracy: 0.9746\n",
            "Epoch 12/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 0.0867 - val_accuracy: 0.9766\n",
            "Epoch 13/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0902 - val_accuracy: 0.9770\n",
            "Epoch 14/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0980 - val_accuracy: 0.9741\n",
            "Epoch 15/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0961 - val_accuracy: 0.9765\n",
            "Epoch 16/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0937 - val_accuracy: 0.9780\n",
            "Epoch 17/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.1005 - val_accuracy: 0.9762\n",
            "Epoch 18/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.0944 - val_accuracy: 0.9790\n",
            "Epoch 19/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0926 - val_accuracy: 0.9790\n",
            "Epoch 20/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0939 - val_accuracy: 0.9799\n",
            "Epoch 21/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.1046 - val_accuracy: 0.9782\n",
            "Epoch 22/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.1009 - val_accuracy: 0.9785\n",
            "Epoch 23/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.1080 - val_accuracy: 0.9779\n",
            "Epoch 24/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.1044 - val_accuracy: 0.9782\n",
            "Epoch 25/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.1038 - val_accuracy: 0.9784\n",
            "Epoch 26/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1041 - val_accuracy: 0.9792\n",
            "Epoch 27/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1085 - val_accuracy: 0.9774\n",
            "Epoch 28/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1154 - val_accuracy: 0.9771\n",
            "Epoch 29/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1194 - val_accuracy: 0.9770\n",
            "Epoch 30/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1281 - val_accuracy: 0.9762\n",
            "Epoch 31/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1172 - val_accuracy: 0.9795\n",
            "Epoch 32/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1236 - val_accuracy: 0.9787\n",
            "Epoch 33/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1128 - val_accuracy: 0.9787\n",
            "Epoch 34/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1435 - val_accuracy: 0.9740\n",
            "Epoch 35/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1247 - val_accuracy: 0.9772\n",
            "Epoch 36/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1211 - val_accuracy: 0.9785\n",
            "Epoch 37/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1181 - val_accuracy: 0.9787\n",
            "Epoch 38/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1238 - val_accuracy: 0.9790\n",
            "Epoch 39/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1236 - val_accuracy: 0.9784\n",
            "Epoch 40/40\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1267 - val_accuracy: 0.9797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ea46a6780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Ajo9qYeucM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}